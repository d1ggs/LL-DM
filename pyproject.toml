[[tool.pdm.source]]
name = "torch-cuda"
url = "https://download.pytorch.org/whl/cu121"
include_packages = ["torch*"]
exclude_packages = ["bar-*"]

[tool.pdm]
distribution = false

[project]
name = "ll-dm"
version = "0.1.0"
description = "Default template for PDM package"
authors = [
    {name = "Diego Piccinotti", email = "elimdor@live.it"},
]
dependencies = [
    "transformers[torch]>=4.36.2,<5",
    "sentencepiece>=0.1.99",
    "accelerate>=0.26.1",
    "chainlit>=1.0.100",
    # "langchain>=0.1.4",
    "loguru>=0.7.2",
    "optimum>=1.16.1",
    "sentence-transformers>=2.2.2,<2.3",
    "unstructured>=0.12.0",
    # "cohere>=4.42",
    # "langchain-openai>=0.0.2.post1",
    "faiss-cpu>=1.7.4",
    # "langchainhub>=0.1.14",
    "llama-index>=0.9.8,<0.11.0",
    # "trulens>=0.13.4",
    # "trulens-eval>=0.18.3",
    "openai>=1.10.0",
    "huggingface-hub>=0.20.3",
    "tiktoken>=0.5.2",
    "qdrant-client>=1.7.1",
    "torch==2.1.2",
    "pydantic<2",
    # "langgraph>=0.0.21",
    "guidance>=0.1.10",
    # "wget>=3.2",
    "llama-index-llms-llama-cpp>=0.1.1",
    "llama-index-embeddings-huggingface>=0.1.1",
    "llama-cpp-python @ file:///${PROJECT_ROOT}/wheels/llama_cpp_python-0.2.39-cp310-cp310-manylinux_2_35_x86_64.whl",
]
requires-python = ">=3.10,<3.11"
readme = "README.md"
license = {text = "MIT"}

[project.optional-dependencies]
notebook = [
    "jupyter>=1.0.0",
    "ipykernel>=6.29.0",
]

lint = [
    "isort>=5.13.2",
    "black>=23.12.1",
    "pylint>=3.0.3",
]
