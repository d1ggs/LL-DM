[[tool.pdm.source]]
name = "torch-cuda"
url = "https://download.pytorch.org/whl/cu121"
include_packages = ["torch*"]
exclude_packages = ["bar-*"]

[tool.pdm]
distribution = false

[project]
name = "ll-dm"
version = "0.1.0"
description = "Default template for PDM package"
authors = [
    {name = "Diego Piccinotti", email = "elimdor@live.it"},
]
dependencies = [
    "transformers[torch]>=4.36.2",
    "sentencepiece>=0.1.99",
    "accelerate>=0.26.1",
    "chainlit>=1.0.100",
    "langchain>=0.1.4",
    "loguru>=0.7.2",
    "optimum>=1.16.1",
    "sentence-transformers>=2.2.2",
    "unstructured>=0.12.0",
    "cohere>=4.42",
    "langchain-openai>=0.0.2.post1",
    "llama-cpp-python<0.2.40",
    "faiss-cpu>=1.7.4",
    "langchainhub>=0.1.14",
    "llama-index>=0.9.8,<0.11.0",
    "trulens>=0.13.4",
    "trulens-eval>=0.18.3",
    # "llama-cpp-python @ https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/wheels/llama_cpp_python-0.2.32+cu121-cp310-cp310-manylinux_2_31_x86_64.whl",
    "openai>=1.10.0",
    "huggingface-hub>=0.20.3",
    "tiktoken>=0.5.2",
    "qdrant-client>=1.7.1",
    "torch==2.1.1",
    "pydantic<2",
    "langgraph>=0.0.21",
    "guidance>=0.1.10",
    "wget>=3.2",
    "llama-index-llms-llama-cpp>=0.1.1",
]
requires-python = ">=3.10,<3.11"
readme = "README.md"
license = {text = "MIT"}

[project.optional-dependencies]
notebook = [
    "jupyter>=1.0.0",
    "ipykernel>=6.29.0",
]

lint = [
    "isort>=5.13.2",
    "black>=23.12.1",
    "pylint>=3.0.3",
]
