{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+rocm5.6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'elements' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/aurorabuilder/elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.prompts import ChatPromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 ROCm devices:\n",
      "  Device 0: AMD Radeon RX 6800, compute capability 10.3, VMM: no\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from models/neural-chat-7b-v3-3.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = intel_neural-chat-7b-v3-3\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = intel_neural-chat-7b-v3-3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "llm_load_tensors: using ROCm for GPU acceleration\n",
      "llm_load_tensors: system memory used  =   86.05 MiB\n",
      "llm_load_tensors: VRAM used           = 4807.05 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32768\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 36.56 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 33.38 MiB\n",
      "llama_new_context_with_model: total VRAM used: 4840.43 MiB (model: 4807.05 MiB, context: 33.38 MiB)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# model = LlamaCpp(\n",
    "#     model_path=\"models/neural-chat-7b-v3-3.Q5_K_M.gguf\",\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=512,\n",
    "#     top_p=0.95,\n",
    "#     # callback_manager=callback_manager,\n",
    "#     verbose=True, # Verbose is required to pass to the callback manager\n",
    "#     n_gpu_layers=-1,\n",
    "#     echo=True,\n",
    "#     n_ctx=1024*32,\n",
    "#     stop=[\"### System\", \"### User\", \"### Assistant\", \"User:\", \"Player:\", \"DM:\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# openai.api_key = \"EMPTY\"\n",
    "# openai.base_url = \"http://localhost:5000/v1/\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1, max_tokens=512, \n",
    "                   openai_api_base=\"http://localhost:5000/v1/\", # Remove this to use the actual OpenAI API\n",
    "                   streaming=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, UnstructuredXMLLoader\n",
    "from langchain_community.document_loaders.unstructured import UnstructuredBaseLoader\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import List, Any\n",
    "\n",
    "class XMLRPGClassLoader(UnstructuredBaseLoader):\n",
    "    \"\"\"Custom Loader for RPG class XML files, focusing on detailed features/abilities.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        mode: str = \"elements\",\n",
    "        **unstructured_kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize with XML file path.\"\"\"\n",
    "        self.file_path = file_path\n",
    "        super().__init__(mode=mode, **unstructured_kwargs)\n",
    "\n",
    "    def _parse_xml(self) -> ET.ElementTree:\n",
    "        \"\"\"Parse the XML file and return the root element.\"\"\"\n",
    "        tree = ET.parse(self.file_path)\n",
    "        return tree.getroot()\n",
    "\n",
    "    def _get_elements(self) -> List[dict]:\n",
    "            \"\"\"Extract elements from the XML file.\"\"\"\n",
    "            root = self._parse_xml()\n",
    "            elements = []\n",
    "\n",
    "            for element in root.findall('.//element'):\n",
    "                element_data = {}\n",
    "                element_texts = []\n",
    "\n",
    "                # Element name and type\n",
    "                name = element.get('name', 'Unnamed Feature')\n",
    "                element_type = element.get('type', 'Unknown Type')\n",
    "                element_texts.append(name)\n",
    "                element_data['type'] = element_type\n",
    "\n",
    "                # Extracting description, sheet, and supports text\n",
    "                for tag in ['description', 'sheet', 'supports']:\n",
    "                    text_content = element.find(tag)\n",
    "                    if text_content is not None:\n",
    "                        text = ''.join(text_content.itertext()).strip()\n",
    "                        element_texts.append(text)\n",
    "\n",
    "                # Combine all texts and add metadata\n",
    "                element_data['text'] = \"\\n\\n\".join(element_texts)\n",
    "                elements.append(element_data)\n",
    "\n",
    "            return elements\n",
    "\n",
    "    def _get_metadata(self) -> dict:\n",
    "        \"\"\"Get metadata for the XML file.\"\"\"\n",
    "        return {\"source\": self.file_path, \"file_type\": \"xml\"}\n",
    "\n",
    "# Example usage\n",
    "# loader = XMLRPGClassLoader(file_path=\"elements/core/players-handbook/classes/class-barbarian.xml\")\n",
    "# docs = loader.load()\n",
    "# docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob  \n",
    "# Define the directory path \n",
    "directory_path = 'elements/core/players-handbook/classes'  \n",
    "# Initialize a list to store the XML file contents as strings \n",
    "xml_strings = []  \n",
    "# Use the glob module to recursively find XML files in the directory and its subfolders \n",
    "xml_files = glob.glob('*.xml', root_dir=directory_path, recursive=True)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    loader = XMLRPGClassLoader(os.path.join(directory_path, xml_file))\n",
    "    documents.extend(loader.load())\n",
    "# Loop through each XML file and read its content as a string \n",
    "# for xml_file in xml_files:     \n",
    "#     with open(os.path.join(directory_path, xml_file), 'r', encoding='utf-8') as file:         \n",
    "#         xml_string = file.read()         \n",
    "#         xml_strings.append(xml_string)  \n",
    "# Now, the xml_strings list contains the contents of all XML files as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"{'type': 'Class', 'text': 'Cleric\\\\n\\\\nArms and eyes upraised toward the sun and a prayer on his lips, an elf begins to glow with an inner light that spills out to heal his battle-worn companions.\\\\n\\\\t\\\\t\\\\tChanting a song of glory, a dwarf swings his axe in wide swaths to cut through the ranks of orcs arrayed against him, shouting praise to the gods with every foe’s fall.\\\\n\\\\t\\\\t\\\\tCalling down a curse upon the forces of undeath, a human lifts her holy symbol as light pours from it to drive back the zombies crowding in on her companions.\\\\n\\\\t\\\\t\\\\tClerics are intermediaries between the mortal world and the distant planes of the gods. As varied as the gods they serve, clerics strive to embody the handiwork of their deities. No ordinary priest, a cleric is imbued with divine magic.\\\\n\\\\t\\\\t\\\\tHEALERS AND WARRIORS\\\\n\\\\t\\\\t\\\\tDivine magic, as the name suggests, is the power of the gods, flowing from them into the world. Clerics are conduits for that power, manifesting it as miraculous effects. The gods don’t grant this power to everyone who seeks it, but only to those chosen to fulfill a high calling.\\\\n\\\\t\\\\t\\\\tHarnessing divine magic doesn’t rely on study or training. A cleric might learn formulaic prayers and ancient rites, but the ability to cast cleric spells relies on devotion and an intuitive sense of a deity’s wishes.\\\\n\\\\t\\\\t\\\\tClerics combine the helpful magic of healing and inspiring their allies with spells that harm and hinder foes. They can provoke awe and dread, lay curses of plague or poison, and even call down flames from heaven to consume their enemies. For those evildoers who will benefit most from a mace to the head, clerics depend on their combat training to let them wade into melee with the power of the gods on their side.\\\\n\\\\t\\\\t\\\\tDIVINE AGENTS\\\\n\\\\t\\\\t\\\\tNot every acolyte or officiant at a temple or shrine is a cleric. Some priests are called to a simple life of temple service, carrying out their gods’ will through prayer and sacrifice, not by magic and strength of arms. In some cities, priesthood amounts to a political office, viewed as a stepping stone to higher positions of authority and involving no communion with a god at all. True clerics are rare in most hierarchies.\\\\n\\\\t\\\\t\\\\tWhen a cleric takes up an adventuring life, it is usually because his or her god demands it. Pursuing the goals of the gods often involves braving dangers beyond the walls of civilization, smiting evil or seeking holy relics in ancient tombs. Many clerics are also expected to protect their deities’ worshipers, which can mean fighting rampaging orcs, negotiating peace between warring nations, or sealing a portal that would allow a demon prince to enter the world.\\\\n\\\\t\\\\t\\\\tMost adventuring clerics maintain some connection to established temples and orders of their faiths. A temple might ask for a cleric’s aid, or a high priest might be in a position to demand it.\\\\n\\\\t\\\\t\\\\tCREATING A CLERIC\\\\n\\\\t\\\\t\\\\tAs you create a cleric, the most important question to consider is which deity to serve and what principles you want your character to embody. The Player’s Handbook includes lists of many of the gods of the multiverse. Check with your DM to learn which deities are in your campaign.\\\\n\\\\t\\\\t\\\\tOnce you’ve chosen a deity, consider your cleric’s relationship to that god. Did you enter this service willingly? Or did the god choose you, impelling you into service with no regard for your wishes? How do the temple priests of your faith regard you: as a champion or a troublemaker? What are your ultimate goals? Does your deity have a special task in mind for you? Or are you striving to prove yourself worthy of a great quest?\\\\n\\\\t\\\\t\\\\tQUICK BUILD\\\\n\\\\t\\\\t\\\\tYou can make a cleric quickly by following these suggestions. First, Wisdom should be your highest ability score, followed by Strength or Constitution. Second, choose the acolyte background.\\\\n\\\\t\\\\t\\\\tCLASS FEATURES\\\\n\\\\t\\\\t\\\\tAs a cleric, you gain the following class features.\\\\n\\\\t\\\\t\\\\tHIT POINTS\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\tHit Dice: 1d8 per cleric level\\\\n\\\\t\\\\t\\\\t\\\\tHit Points at 1st Level: 8 + your Constitution modifier\\\\n\\\\t\\\\t\\\\t\\\\tHit Points at Higher Levels: 1d8 (or 5) + your Constitution modifier per cleric level after 1st \\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\tPROFICIENCIES\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\tArmor: Light armor, medium armor, shield\\\\n\\\\t\\\\t\\\\t\\\\tWeapons: Simple weapons\\\\n\\\\t\\\\t\\\\t\\\\tTools: None\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\tSaving Throws: Wisdom, Charisma\\\\n\\\\t\\\\t\\\\t\\\\tSkills: Choose two from History, Insight, Medicine, Persuasion, and Religion\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\tEQUIPMENT\\\\n\\\\t\\\\t\\\\tYou start with the following equipment, in addition to the equipment granted by your background:\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t(a) a mace or (b) a warhammer (if proficient) \\\\n\\\\t\\\\t\\\\t\\\\t(a) scale mail, (b) leather armor, or (c) chain mail (if proficient) \\\\n\\\\t\\\\t\\\\t\\\\t(a) a light crossbow and 20 bolts or (b) any simple weapon \\\\n\\\\t\\\\t\\\\t\\\\t(a) a priest’s pack or (b) an explorer’s pack \\\\n\\\\t\\\\t\\\\t\\\\tA shield and a holy symbol\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\tTHE CLERIC\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\tLevelFeaturesCantrips Known1st2nd3rd4th5th6th7th8th9th\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t 1stSpellcasting, Divine Domain32————————\\\\n\\\\t\\\\t\\\\t\\\\t 2ndChannel Divinity (1/rest), Divine Domain feature33————————\\\\n\\\\t\\\\t\\\\t\\\\t 3rd—342———————\\\\n\\\\t\\\\t\\\\t\\\\t 4thAbility Score Improvement443———————\\\\n\\\\t\\\\t\\\\t\\\\t 5thDestroy Undead (CR 1/2)4432——————\\\\n\\\\t\\\\t\\\\t\\\\t 6thChannel Divinity (2/rest), Divine Domain feature4433——————\\\\n\\\\t\\\\t\\\\t\\\\t 7th—44331—————\\\\n\\\\t\\\\t\\\\t\\\\t 8thAbility Score Improvement, Destroy Undead (CR 1), Divine Domain feature44332—————\\\\n\\\\t\\\\t\\\\t\\\\t 9th—443331————\\\\n\\\\t\\\\t\\\\t\\\\t10thDivine Intervention543332————\\\\n\\\\t\\\\t\\\\t\\\\t11thDestroy Undead (CR 2)5433321———\\\\n\\\\t\\\\t\\\\t\\\\t12thAbility Score Improvement5433321———\\\\n\\\\t\\\\t\\\\t\\\\t13th—54333211——\\\\n\\\\t\\\\t\\\\t\\\\t14thDestroy Undead (CR 3)54333211——\\\\n\\\\t\\\\t\\\\t\\\\t15th—543332111—\\\\n\\\\t\\\\t\\\\t\\\\t16thAbility Score Improvement543332111—\\\\n\\\\t\\\\t\\\\t\\\\t17thDestroy Undead (CR 4), Divine Domain feature5433321111\\\\n\\\\t\\\\t\\\\t\\\\t18thChannel Divinity (3/rest)5433331111\\\\n\\\\t\\\\t\\\\t\\\\t19thAbility Score Improvement5433332111\\\\n\\\\t\\\\t\\\\t\\\\t20thDivine Intervention Improvement5433332211\\\\n\\\\nA priestly champion who wields divine magic in service of a higher power.'}\", metadata={'source': 'elements/core/players-handbook/classes/class-cleric.xml', 'file_type': 'xml'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=128, chunk_overlap=30, separator=\"\\n\")\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents=documents)\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store\n",
    "Let's load the document inside the FAISS vector store. Pay attention that the metadata will be discarded, so include everything that would be relevant to the model inside the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_texts = [doc.page_content for doc in documents]\n",
    "vectorstore = FAISS.from_texts(texts=document_texts, embedding=hf)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking\n",
    "Vector stores' performance can be increased by reranking the documents extracted with the embeddings by using a dedicated reranking model. The output of such a model will be an ordered subset of the input documents retrieved by the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Optional, Sequence\n",
    "from langchain.schema import Document\n",
    "from langchain.pydantic_v1 import Extra, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from langchain.retrievers.document_compressors.base import BaseDocumentCompressor\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "# from config import bge_reranker_large\n",
    "\n",
    "class BgeRerank(BaseDocumentCompressor):\n",
    "    model_name: str = 'BAAI/bge-reranker-large'  \n",
    "    \"\"\"Model name to use for reranking.\"\"\"    \n",
    "    top_n: int = 10   \n",
    "    \"\"\"Number of documents to return.\"\"\"\n",
    "    model: CrossEncoder = CrossEncoder(model_name, device=\"cuda\")\n",
    "    \"\"\"CrossEncoder instance to use for reranking.\"\"\"\n",
    "\n",
    "    def bge_rerank(self,query,docs):\n",
    "        model_inputs =  [[query, doc] for doc in docs]\n",
    "        scores = self.model.predict(model_inputs)\n",
    "        results = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        return results[:self.top_n]\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def compress_documents(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        query: str,\n",
    "        callbacks: Optional[Callbacks] = None,\n",
    "    ) -> Sequence[Document]:\n",
    "        \"\"\"\n",
    "        Compress documents using BAAI/bge-reranker models.\n",
    "\n",
    "        Args:\n",
    "            documents: A sequence of documents to compress.\n",
    "            query: The query to use for compressing the documents.\n",
    "            callbacks: Callbacks to run during the compression process.\n",
    "\n",
    "        Returns:\n",
    "            A sequence of compressed documents.\n",
    "        \"\"\"\n",
    "        if len(documents) == 0:  # to avoid empty api call\n",
    "            return []\n",
    "        doc_list = list(documents)\n",
    "        _docs = [d.page_content for d in doc_list]\n",
    "        results = self.bge_rerank(query, _docs)\n",
    "        final_results = []\n",
    "        for r in results:\n",
    "            doc = doc_list[r[0]]\n",
    "            doc.metadata[\"relevance_score\"] = r[1]\n",
    "            final_results.append(doc)\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compressor = BgeRerank(top_n=5)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever.get_relevant_documents(query=\"Barbarian history proficiency\")\n",
    "context = str(compression_retriever.get_relevant_documents(query=\"Barbarian history proficiency\"))\n",
    "\n",
    "# Sanitize context to be used in a formattable string\n",
    "context = context.replace(\"{\", \"{{\").replace(\"}\", \"}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"### System:\n",
    "Answer the user's question based only on the following context:\n",
    "{context}\n",
    "\n",
    "### User: Question: {question}\n",
    "\n",
    "### Assistant:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": compression_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nA bard's most important skill lies in their ability to weave magic through words and music. Their versatility, knowledge, and talent in various subjects make them masters of performance, speech, and the magic they contain. Bards are known for their skill in inspiring allies, demoralizing foes, manipulating minds, creating illusions, and even healing wounds through their spells and powers. Their strength lies in their sheer versatility and the depth of knowledge they possess, making them valuable assets in any adventuring party.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's a bard's most important skill?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
